services:
  # Backing services.
  mysql:
    # Pin the version for mysql_native_password support.
    image: mysql:8.0.20
    labels:
      com.datadoghq.ad.init_configs: '[{}]'
      com.datadoghq.ad.instances: '[{"host":"%%host%%", "port": "%%port%%"}]'
      com.datadoghq.ad.logs: '[{"source": "mysql", "service": "mysql"}]'
      com.datadoghq.tags.env: "production"
      com.datadoghq.tags.service: "mysql"
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: ${MYSQL_DATABASE}
      MYSQL_USER: ${MYSQL_USER}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
      MYSQL_TCP_PORT: ${MYSQL_PORT}
    # This is required for API and hanayo.
    command: mysqld --default-authentication-plugin=mysql_native_password
    ports:
      - "${MYSQL_PORT}:${MYSQL_PORT}"
    volumes:
      - ${MYSQL_DATA_PATH}:/var/lib/mysql
    healthcheck:
      test: "/usr/bin/mysql --user=$$MYSQL_USER --password=$$MYSQL_PASSWORD --execute \"SELECT 1;\""
      interval: 2s
      timeout: 20s
      retries: 10

  redis:
    logging:
      driver: none
    image: redis
    restart: always
    command: "redis-server --port ${REDIS_PORT}"
    ports:
      - "${REDIS_PORT}:${REDIS_PORT}"
    volumes:
      - ${REDIS_DATA_PATH}:/data
    healthcheck:
      test: "redis-cli -p ${REDIS_PORT} ping"
      interval: 2s
      timeout: 20s
      retries: 10

  rabbitmq:
    image: rabbitmq
    restart: always
    ports:
      # TODO: change default port through envs? Couldnt find it.
      - "5672:5672"
    environment:
      - RABBITMQ_DEFAULT_USER=${RABBITMQ_USER}
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_PASSWORD}
    healthcheck:
      test: rabbitmq-diagnostics -q ping && rabbitmq-diagnostics -q status
      interval: 2s
      timeout: 20s
      retries: 10

  nginx:
    image: rosu-nginx:latest
    restart: always
    ports:
      - "${NGINX_PORT}:80"
    healthcheck:
      test: "curl --fail http://nginx"
      interval: 2s
      timeout: 20s
      retries: 10
    env_file:
      - .env
    volumes:
      - "${DATA_SCREENSHOTS_PATH}:/app/data/screenshots:ro"
      - "${DATA_AVATARS_PATH}:/app/data/avatars:ro"
    depends_on:
      peppy:
        condition: service_healthy
      ussr:
        condition: service_healthy
      api:
        condition: service_healthy
      frontend:
        condition: service_healthy
      panel:
        condition: service_healthy
      performance-service:
        condition: service_healthy
      statistics-service:
        condition: service_healthy
      beatmaps-service:
        condition: service_healthy

  # Jobs
  migrator:
    image: migrator:latest
    restart: no
    depends_on:
      mysql:
        condition: service_healthy
    volumes:
      # So we don't have to rebuild the image per migration.
      - ./migrator/migrations:/app/migrations:ro
    environment:
      - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}
      - MYSQL_DATABASE=${MYSQL_DATABASE}
      - MYSQL_TCP_PORT=${MYSQL_PORT}
  
  # RealistikOsu Services.
  peppy:
    image: peppy:latest
    restart: always
    labels:
      com.datadoghq.ad.init_configs: '[{}]'
      com.datadoghq.ad.instances: '[{"host":"%%host%%", "port": "%%port%%"}]'
      com.datadoghq.ad.logs: '[{"source": "peppy", "service": "peppy"}]'
      com.datadoghq.tags.env: "production"
      com.datadoghq.tags.service: "peppy"
    depends_on:
      mysql:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrator:
        condition: service_completed_successfully
    healthcheck:
      test: "curl --fail ${PEPPY_INTERNAL_URL}:${PEPPY_PORT}"
      interval: 2s
      timeout: 20s
      retries: 10
    ports:
      - "${PEPPY_PORT}:${PEPPY_PORT}"
    volumes:
      - "${DATA_MAPS_PATH}:/data/maps"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - HTTP_PORT=${PEPPY_PORT}
      - HTTP_ADDRESS=0.0.0.0
      - HTTP_THREAD_COUNT=${PEPPY_HTTP_THREAD_COUNT}
      - HTTP_USING_CLOUDFLARE=${PS_USING_CLOUDFLARE}
      
      - MYSQL_HOST=mysql
      - MYSQL_PORT=${MYSQL_PORT}
      - MYSQL_USER=${MYSQL_USER}
      - MYSQL_PASSWORD=${MYSQL_PASSWORD}
      - MYSQL_DATABASE=${MYSQL_DATABASE}
      - MYSQL_POOL_SIZE=${PEPPY_MYSQL_POOL_SIZE}

      - REDIS_HOST=redis
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - REDIS_DB=${REDIS_DATABASE}

      - PERFORMANCE_SERVICE_URL=${PERFORMANCE_SERVICE_INTERNAL_URL}:${PERFORMANCE_SERVICE_PORT}

      - DISCORD_RANKED_WEBHOOK_URL=${PS_DISCORD_RANKED_WEBHOOK}

      - SERVICE_READINESS_TIMEOUT=${SERVICE_READINESS_TIMEOUT}

      - PS_NAME=${PS_SERVER_NAME}
      - PS_DOMAIN=${PS_SERVER_DOMAIN}
      - PS_BOT_USERNAME=${PS_SERVER_BOT_NAME}
      - PS_BOT_USER_ID=${PS_SERVER_BOT_USER_ID}
      - PS_MINIMUM_CLIENT_YEAR=${PEPPY_MINIMUM_CLIENT_YEAR}
      - PS_ENABLE_PY_COMMAND=${PEPPY_PYTHON_COMMAND_ENABLE}
      - PS_PY_COMMAND_WHITELIST=${PEPPY_PYTHON_COMMAND_WHITELIST}

      - DATA_BEATMAP_DIRECTORY=/data/maps
      - IP2LOCATION_API_KEY=${IP2LOCATION_API_KEY}

      - DD_AGENT_HOST=host.docker.internal
      - DD_SERVICE=peppy
      - DD_ENV=production
      - DD_LOGS_INJECTION=true
      - DD_VERSION=4.0.0
  ussr:
    image: ussr:latest
    restart: always
    labels:
      com.datadoghq.ad.init_configs: '[{}]'
      com.datadoghq.ad.instances: '[{"host":"%%host%%", "port": "%%port%%"}]'
      com.datadoghq.ad.logs: '[{"source": "ussr", "service": "ussr"}]'
      com.datadoghq.tags.env: "production"
      com.datadoghq.tags.service: "ussr"
    depends_on:
      mysql:
        condition: service_healthy
      redis:
        condition: service_healthy
      performance-service:
        condition: service_healthy
      migrator:
        condition: service_completed_successfully
    ports:
      - "${USSR_PORT}:${USSR_PORT}"
    healthcheck:
      test: "curl --fail ${USSR_INTERNAL_URL}:${USSR_PORT}/web/bancho-connect.php"
      interval: 2s
      timeout: 20s
      retries: 10
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - HTTP_PORT=${USSR_PORT}
      
      - MYSQL_HOST=mysql
      - MYSQL_PORT=${MYSQL_PORT}
      - MYSQL_USER=${MYSQL_USER}
      - MYSQL_DATABASE=${MYSQL_DATABASE}
      - MYSQL_PASSWORD=${MYSQL_PASSWORD}

      - REDIS_HOST=redis
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - REDIS_DB=${REDIS_DATABASE}

      - DATA_BEATMAP_DIRECTORY=/data/maps
      - DATA_SCREENSHOT_DIRECTORY=/data/screenshots
      - DATA_REPLAY_DIRECTORY=/data/replays

      - API_KEYS_POOL=${OSU_API_KEY_POOL}
      - API_FALLBACK_URL=${USSR_API_FALLBACK_URL}
      - API_OSU_FALLBACK_URL=${USSR_OSU_FALLBACK_URL}
      - DIRECT_URL=${BEATMAPS_SERVICE_INTERNAL_URL}:${BEATMAPS_SERVICE_PORT}/api

      - SERVICE_READINESS_TIMEOUT=${SERVICE_READINESS_TIMEOUT}

      - SRV_URL=${PS_SERVER_DOMAIN}
      - SRV_NAME=${PS_SERVER_NAME}
      - SRV_VERIFIED_BADGE=${PS_VERIFIED_BADGE_ID}
      - BOT_USER_ID=${PS_SERVER_BOT_USER_ID}
      - CUSTOM_CLIENTS=${USSR_ALLOW_CUSTOM_CLIENTS}

      - DISCORD_FIRST_PLACE=${PS_DISCORD_FIRST_PLACE_WEBHOOK}
      - DISCORD_ADMIN_HOOK=${PS_DISCORD_ADMIN_WEBHOOK}

      - WS_WRITE_KEY=${USSR_WEBSOCKET_WRITE_KEY}

      - PERFORMANCE_SERVICE_URL=${PERFORMANCE_SERVICE_INTERNAL_URL}:${PERFORMANCE_SERVICE_PORT}
      
      # TODO: we dont use these atm lol.
      - S3_ENABLED=false
      - S3_BUCKET=
      - S3_REGION=
      - S3_ENDPOINT=
      - S3_ACCESS_KEY=
      - S3_SECRET_KEY=

      - MEILI_DIRECT=false
      - MEILI_URL=
      - MEILI_KEY=

      - DD_AGENT_HOST=host.docker.internal
      - DD_SERVICE=ussr
      - DD_ENV=production
      - DD_LOGS_INJECTION=true
      - DD_VERSION=4.0.0

    volumes:
      - ${DATA_REPLAYS_PATH}:/data/replays
      - ${DATA_SCREENSHOTS_PATH}:/data/screenshots
      - ${DATA_MAPS_PATH}:/data/maps
  
  api:
    image: api:latest
    restart: always
    labels:
      com.datadoghq.ad.init_configs: '[{}]'
      com.datadoghq.ad.instances: '[{"host":"%%host%%", "port": "%%port%%"}]'
      com.datadoghq.ad.logs: '[{"source": "RippleAPI", "service": "RippleAPI"}]'
      com.datadoghq.tags.env: "production"
      com.datadoghq.tags.service: "RippleAPI"
    depends_on:
      mysql:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrator:
        condition: service_completed_successfully
    healthcheck:
      test: "curl --fail ${API_INTERNAL_URL}:${API_PORT}/api/v1/ping"
      interval: 2s
      timeout: 20s
      retries: 10
    ports:
      - "${API_PORT}:${API_PORT}"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - APP_COMPONENT=api
      - APP_ENV=production
      - APP_PORT=${API_PORT}

      - HANAYO_KEY=${HANAYO_KEY}
      
      - BEATMAP_REQUESTS_PER_USER=${BEATMAP_REQUESTS_PER_USER}
      - RANK_QUEUE_SIZE=${RANK_QUEUE_SIZE}

      - OSU_API_KEY=${OSU_API_KEY}

      - DB_SCHEME=mysql
      - DB_HOST=mysql
      - DB_PORT=${MYSQL_PORT}
      - DB_USER=${MYSQL_USER}
      - DB_PASS=${MYSQL_PASSWORD}
      - DB_NAME=${MYSQL_DATABASE}

      - REDIS_HOST=redis
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_PASS=${REDIS_PASSWORD}
      - REDIS_DB=${REDIS_DATABASE}

      - DD_AGENT_HOST=host.docker.internal
      - DD_SERVICE=RippleAPI
      - DD_ENV=production
      - DD_LOGS_INJECTION=true
      - DD_VERSION=4.0.0
    
  frontend:
    image: frontend:latest
    restart: always
    labels:
      com.datadoghq.ad.init_configs: '[{}]'
      com.datadoghq.ad.instances: '[{"host":"%%host%%", "port": "%%port%%"}]'
      com.datadoghq.ad.logs: '[{"source": "frontend", "service": "frontend"}]'
      com.datadoghq.tags.env: "production"
      com.datadoghq.tags.service: "frontend"
    depends_on:
      mysql:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrator:
        condition: service_completed_successfully
      api:
        condition: service_healthy
    healthcheck:
      test: "curl --fail ${FRONTEND_INTERNAL_URL}:${FRONTEND_PORT}/favicon.ico"
      interval: 2s
      timeout: 20s
      retries: 10
    ports:
      - "${FRONTEND_PORT}:${FRONTEND_PORT}"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - APP_COMPONENT=api
      - APP_ENV=production
      - APP_COOKIE_SECRET=${COOKIE_SECRET}
      - APP_PORT=${FRONTEND_PORT}
      - APP_HANAYO_KEY=${HANAYO_KEY}
      - APP_INTERNAL_AVATARS_PATH=/data/avatars
      - APP_BASE_URL=${APP_BASE_URL}
      - APP_AVATAR_URL=${APP_AVATAR_URL}
      - APP_API_URL=${APP_API_URL}
      - APP_BANCHO_URL=${APP_BANCHO_URL}

      - BEATMAP_MIRROR_API_URL=${BEATMAP_MIRROR_API_URL}
      - BEATMAP_DOWNLOAD_MIRROR_URL=${BEATMAP_DOWNLOAD_MIRROR_URL}

      - DISCORD_SERVER_URL=${DISCORD_SERVER_URL}
      - DISCORD_APP_CLIENT_ID=${DISCORD_APP_CLIENT_ID}
      - DISCORD_APP_CLIENT_SECRET=${DISCORD_APP_CLIENT_SECRET}
      
      - DB_SCHEME=mysql
      - DB_HOST=mysql
      - DB_PORT=${MYSQL_PORT}
      - DB_USER=${MYSQL_USER}
      - DB_PASS=${MYSQL_PASSWORD}
      - DB_NAME=${MYSQL_DATABASE}
      
      - REDIS_MAX_CONNECTIONS=10
      - REDIS_NETWORK_TYPE=tcp
      - REDIS_HOST=redis
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_PASS=${REDIS_PASSWORD}
      - REDIS_DB=${REDIS_DATABASE}
      - REDIS_USE_SSL=false
      
      - MAILGUN_DOMAIN=${MAILGUN_DOMAIN}
      - MAILGUN_API_KEY=${MAILGUN_API_KEY}
      - MAILGUN_PUBLIC_KEY=${MAILGUN_PUBLIC_KEY}
      - MAILGUN_FROM=${MAILGUN_FROM}

      - RECAPTCHA_SITE_KEY=${RECAPTCHA_SITE_KEY}
      - RECAPTCHA_SECRET_KEY=${RECAPTCHA_SECRET_KEY}

      - IP_LOOKUP_URL=${IP_LOOKUP_URL}
      - DISCORD_USER_LOOKUP_URL=${DISCORD_USER_LOOKUP_URL}

      - PAYPAL_EMAIL_ADDRESS=${PAYPAL_EMAIL_ADDRESS}

      - DD_AGENT_HOST=host.docker.internal
      - DD_SERVICE=peppy
      - DD_ENV=frontend
      - DD_LOGS_INJECTION=true
      - DD_VERSION=4.0.0

    volumes:
      - ${DATA_AVATARS_PATH}:/data/avatars

  panel:
    image: panel:latest
    restart: always
    labels:
      com.datadoghq.ad.init_configs: '[{}]'
      com.datadoghq.ad.instances: '[{"host":"%%host%%", "port": "%%port%%"}]'
      com.datadoghq.ad.logs: '[{"source": "admin-panel", "service": "admin-panel"}]'
      com.datadoghq.tags.env: "production"
      com.datadoghq.tags.service: "admin-panel"
    depends_on:
      mysql:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrator:
        condition: service_completed_successfully
    healthcheck:
      test: "curl --fail ${PANEL_INTERNAL_URL}:${PANEL_PORT}"
      interval: 2s
      timeout: 20s
      retries: 10
    ports:
      - "${PANEL_PORT}:${PANEL_PORT}"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - USE_ENV_CONFIG=true
      
      - HTTP_PORT=${PANEL_PORT}
      - HTTP_HOST=0.0.0.0
      - SQL_HOST=mysql
      - SQL_PORT=${MYSQL_PORT}
      - SQL_USER=${MYSQL_USER}
      - SQL_PASSWORD=${MYSQL_PASSWORD}
      - SQL_DATABASE=${MYSQL_DATABASE}
      - REDIS_HOST=redis
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_DB=${REDIS_DATABASE}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - SRV_NAME=${PS_SERVER_NAME}
      - SRV_URL=${APP_BASE_URL}/
      - SRV_SUPPORTS_RELAX=true
      - SRV_SUPPORTS_AUTOPILOT=true
      - SRV_DONOR_BADGE=${PS_DONATOR_BADGE_ID}
      - API_USSR_URL=${APP_USSR_URL}/
      - API_AVATAR_URL=${APP_AVATAR_URL}/
      - API_BANCHO_URL=${APP_BANCHO_URL}/
      - WEBHOOK_RANKED=${PS_DISCORD_RANKED_WEBHOOK}
      - WEBHOOK_ADMIN_LOG=${PS_DISCORD_ADMIN_WEBHOOK}

      - DD_AGENT_HOST=host.docker.internal
      - DD_SERVICE=admin-panel
      - DD_ENV=production
      - DD_LOGS_INJECTION=true
      - DD_VERSION=4.0.0
  
  performance-service:
    image: performance-service:latest
    restart: always
    labels:
      com.datadoghq.ad.init_configs: '[{}]'
      com.datadoghq.ad.instances: '[{"host":"%%host%%", "port": "%%port%%"}]'
      com.datadoghq.ad.logs: '[{"source": "performance-service", "service": "performance-service"}]'
      com.datadoghq.tags.env: "production"
      com.datadoghq.tags.service: "performance-service"
    depends_on:
      mysql:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      migrator:
        condition: service_completed_successfully
    healthcheck:
      test: "curl --fail ${PERFORMANCE_SERVICE_INTERNAL_URL}:${PERFORMANCE_SERVICE_PORT}/api/v1/status"
      interval: 2s
      timeout: 20s
      retries: 10
    ports:
      - "${PERFORMANCE_SERVICE_PORT}:${PERFORMANCE_SERVICE_PORT}"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - APP_COMPONENT=api
      
      - API_HOST=0.0.0.0
      - API_PORT=${PERFORMANCE_SERVICE_PORT}

      - MYSQL_USER=${MYSQL_USER}
      - MYSQL_PASSWORD=${MYSQL_PASSWORD}
      - MYSQL_HOST=mysql
      - MYSQL_PORT=${MYSQL_PORT}
      - MYSQL_DATABASE=${MYSQL_DATABASE}

      - AMQP_USER=${RABBITMQ_USER}
      - AMQP_PASSWORD=${RABBITMQ_PASSWORD}
      - AMQP_HOST=rabbitmq
      - AMQP_PORT=5672

      - REDIS_USER=redis
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - REDIS_DB=${REDIS_DATABASE}
      - REDIS_HOST=redis
      - REDIS_PORT=${REDIS_PORT}

      - BEATMAPS_PATH=/data/maps

      # Enable any/all prints.
      - RUST_LOG=performance_service=debug
      - DD_AGENT_HOST=host.docker.internal
      - DD_SERVICE=performance-service
      - DD_ENV=production
      - DD_LOGS_INJECTION=true
      - DD_VERSION=4.0.0

    volumes:
      - ${DATA_MAPS_PATH}:/data/maps

  statistics-service:
    image: statistics-service:latest
    restart: always
    labels:
      com.datadoghq.ad.init_configs: '[{}]'
      com.datadoghq.ad.instances: '[{"host":"%%host%%", "port": "%%port%%"}]'
      com.datadoghq.ad.logs: '[{"source": "StatisticsService", "service": "StatisticsService"}]'
      com.datadoghq.tags.env: "production"
      com.datadoghq.tags.service: "StatisticsService"
    depends_on:
      mysql:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrator:
        condition: service_completed_successfully
      statistics-service-online-cron:
        condition: service_started
      statistics-service-profile-graphs-cron:
        condition: service_started
      statistics-service-top-scores-cron:
        condition: service_started
    healthcheck:
      test: "curl --fail ${STATISTICS_SERVICE_INTERNAL_URL}:${STATISTICS_SERVICE_PORT}/api/v1/statistics/homepage"
      interval: 2s
      timeout: 20s
      retries: 10
    ports:
      - "${STATISTICS_SERVICE_PORT}:${STATISTICS_SERVICE_PORT}"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - APP_ENV=production
      - APP_COMPONENT=api
      - APP_HOST=0.0.0.0
      - APP_PORT=${STATISTICS_SERVICE_PORT}
      

      - WRITE_DB_HOST=mysql
      - WRITE_DB_PORT=${MYSQL_PORT}
      - WRITE_DB_USER=${MYSQL_USER}
      - WRITE_DB_PASS=${MYSQL_PASSWORD}
      - WRITE_DB_NAME=${MYSQL_DATABASE}

      - READ_DB_HOST=mysql
      - READ_DB_PORT=${MYSQL_PORT}
      - READ_DB_USER=${MYSQL_USER}
      - READ_DB_PASS=${MYSQL_PASSWORD}
      - READ_DB_NAME=${MYSQL_DATABASE}

      - REDIS_HOST=redis
      - REDIS_PORT=${REDIS_PORT}

      - SERVICE_READINESS_TIMEOUT=${SERVICE_READINESS_TIMEOUT}

      - LOG_LEVEL=10

      - DD_AGENT_HOST=host.docker.internal
      - DD_SERVICE=statistics-service
      - DD_ENV=production
      - DD_LOGS_INJECTION=true
      - DD_VERSION=4.0.0

  beatmaps-service:
    image: beatmaps-service:latest
    restart: always
    labels:
      com.datadoghq.ad.init_configs: '[{}]'
      com.datadoghq.ad.instances: '[{"host":"%%host%%", "port": "%%port%%"}]'
      com.datadoghq.ad.logs: '[{"source": "BeatmapsService", "service": "BeatmapsService"}]'
      com.datadoghq.tags.env: "production"
      com.datadoghq.tags.service: "BeatmapsService"
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: "curl --fail ${BEATMAPS_SERVICE_INTERNAL_URL}:${BEATMAPS_SERVICE_PORT}/_health"
      interval: 2s
      timeout: 20s
      retries: 10
    ports:
      - "${BEATMAPS_SERVICE_PORT}:${BEATMAPS_SERVICE_PORT}"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - APP_ENV=production
      - ServiceHost=0.0.0.0
      - ServicePort=${BEATMAPS_SERVICE_PORT}
      - ClientId=${OSU_CLIENT_ID}
      - ClientSecret=${OSU_CLIENT_SECRET}
      # ?
      - RedisConnectionString=redis:${REDIS_PORT}
      - DD_AGENT_HOST=host.docker.internal
      - DD_SERVICE=beatmaps-service
      - DD_ENV=production
      - DD_LOGS_INJECTION=true
      - DD_VERSION=4.0.0

  donor-bot:
    image: donor-bot:latest
    restart: always
    labels:
      com.datadoghq.ad.init_configs: '[{}]'
      com.datadoghq.ad.instances: '[{"host":"%%host%%", "port": "%%port%%"}]'
      com.datadoghq.ad.logs: '[{"source": "DonorBot", "service": "DonorBot"}]'
      com.datadoghq.tags.env: "production"
      com.datadoghq.tags.service: "DonorBot"
    depends_on:
      mysql:
        condition: service_healthy
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - APP_ENV=production
      - APP_COMPONENT=bot
      - SERVICE_READINESS_TIMEOUT=${SERVICE_READINESS_TIMEOUT}
      - DISCORD_TOKEN=${DISCORD_TOKEN}

      - ROSU_DISCORD_GUILD_ID=${ROSU_DISCORD_GUILD_ID}
      - ROSU_DISCORD_DONOR_ROLE_ID=${ROSU_DISCORD_GUILD_ID}
      - ROSU_DISCORD_ADMIN_LOGS_CHANNEL_ID=${ROSU_DISCORD_GUILD_ID}

      - READ_DB_SCHEME=mysql
      - READ_DB_USER=${MYSQL_USER}
      - READ_DB_PASS=${MYSQL_PASSWORD}
      - READ_DB_HOST=mysql
      - READ_DB_PORT=${MYSQL_PORT}
      - READ_DB_NAME=${MYSQL_DATABASE}
      - READ_DB_USE_SSL=false
      - READ_DB_CA_CERTIFICATE=
      - INITIALLY_AVAILABLE_READ_DB=${MYSQL_DATABASE}

      - DB_POOL_MIN_SIZE=${DB_POOL_MIN_SIZE}
      - DB_POOL_MAX_SIZE=${DB_POOL_MAX_SIZE}

      - DD_AGENT_HOST=host.docker.internal
      - DD_SERVICE=donor-bot
      - DD_ENV=production
      - DD_LOGS_INJECTION=true
      - DD_VERSION=4.0.0
    
  # Daemons
  statistics-service-online-cron:
    image: statistics-service:latest
    restart: always
    labels:
      com.datadoghq.ad.init_configs: '[{}]'
      com.datadoghq.ad.instances: '[{"host":"%%host%%", "port": "%%port%%"}]'
      com.datadoghq.ad.logs: '[{"source": "StatisticsServiceCron-Online", "service": "StatisticsServiceCron-Online"}]'
      com.datadoghq.tags.env: "production"
      com.datadoghq.tags.service: "StatisticsServiceCron-Online"
    depends_on:
      mysql:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrator:
        condition: service_completed_successfully
    environment:
      - APP_ENV=production
      - APP_COMPONENT=online_cron
      - APP_HOST=0.0.0.0
      - APP_PORT=${STATISTICS_SERVICE_PORT}
      

      - WRITE_DB_HOST=mysql
      - WRITE_DB_PORT=${MYSQL_PORT}
      - WRITE_DB_USER=${MYSQL_USER}
      - WRITE_DB_PASS=${MYSQL_PASSWORD}
      - WRITE_DB_NAME=${MYSQL_DATABASE}

      - READ_DB_HOST=mysql
      - READ_DB_PORT=${MYSQL_PORT}
      - READ_DB_USER=${MYSQL_USER}
      - READ_DB_PASS=${MYSQL_PASSWORD}
      - READ_DB_NAME=${MYSQL_DATABASE}

      - REDIS_HOST=redis
      - REDIS_PORT=${REDIS_PORT}

      - SERVICE_READINESS_TIMEOUT=${SERVICE_READINESS_TIMEOUT}

      - LOG_LEVEL=10

      - DD_AGENT_HOST=host.docker.internal
      - DD_SERVICE=statistics-service-online
      - DD_ENV=production
      - DD_LOGS_INJECTION=true
      - DD_VERSION=4.0.0
  
  statistics-service-profile-graphs-cron:
    image: statistics-service:latest
    restart: always
    labels:
      com.datadoghq.ad.init_configs: '[{}]'
      com.datadoghq.ad.instances: '[{"host":"%%host%%", "port": "%%port%%"}]'
      com.datadoghq.ad.logs: '[{"source": "StatisticsServiceCron-Graphs", "service": "StatisticsServiceCron-Graphs"}]'
      com.datadoghq.tags.env: "production"
      com.datadoghq.tags.service: "StatisticsServiceCron-Graphs"
    depends_on:
      mysql:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrator:
        condition: service_completed_successfully
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - APP_ENV=production
      - APP_COMPONENT=profile_graphs_cron
      - APP_HOST=0.0.0.0
      - APP_PORT=${STATISTICS_SERVICE_PORT}
      

      - WRITE_DB_HOST=mysql
      - WRITE_DB_PORT=${MYSQL_PORT}
      - WRITE_DB_USER=${MYSQL_USER}
      - WRITE_DB_PASS=${MYSQL_PASSWORD}
      - WRITE_DB_NAME=${MYSQL_DATABASE}

      - READ_DB_HOST=mysql
      - READ_DB_PORT=${MYSQL_PORT}
      - READ_DB_USER=${MYSQL_USER}
      - READ_DB_PASS=${MYSQL_PASSWORD}
      - READ_DB_NAME=${MYSQL_DATABASE}

      - REDIS_HOST=redis
      - REDIS_PORT=${REDIS_PORT}

      - SERVICE_READINESS_TIMEOUT=${SERVICE_READINESS_TIMEOUT}

      - LOG_LEVEL=10

      - DD_AGENT_HOST=host.docker.internal
      - DD_SERVICE=statistics-service-graphs
      - DD_ENV=production
      - DD_LOGS_INJECTION=true
      - DD_VERSION=4.0.0

  statistics-service-top-scores-cron:
    image: statistics-service:latest
    restart: always
    labels:
      com.datadoghq.ad.init_configs: '[{}]'
      com.datadoghq.ad.instances: '[{"host":"%%host%%", "port": "%%port%%"}]'
      com.datadoghq.ad.logs: '[{"source": "StatisticsServiceCron-Top", "service": "StatisticsServiceCron-Top"}]'
      com.datadoghq.tags.env: "production"
      com.datadoghq.tags.service: "StatisticsServiceCron-Top"
    depends_on:
      mysql:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrator:
        condition: service_completed_successfully
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - APP_ENV=production
      - APP_COMPONENT=top_scores_cron
      - APP_HOST=0.0.0.0
      - APP_PORT=${STATISTICS_SERVICE_PORT}
      

      - WRITE_DB_HOST=mysql
      - WRITE_DB_PORT=${MYSQL_PORT}
      - WRITE_DB_USER=${MYSQL_USER}
      - WRITE_DB_PASS=${MYSQL_PASSWORD}
      - WRITE_DB_NAME=${MYSQL_DATABASE}

      - READ_DB_HOST=mysql
      - READ_DB_PORT=${MYSQL_PORT}
      - READ_DB_USER=${MYSQL_USER}
      - READ_DB_PASS=${MYSQL_PASSWORD}
      - READ_DB_NAME=${MYSQL_DATABASE}

      - REDIS_HOST=redis
      - REDIS_PORT=${REDIS_PORT}

      - SERVICE_READINESS_TIMEOUT=${SERVICE_READINESS_TIMEOUT}

      - LOG_LEVEL=10

      - DD_AGENT_HOST=host.docker.internal
      - DD_SERVICE=statistics-service-top
      - DD_ENV=production
      - DD_LOGS_INJECTION=true
      - DD_VERSION=4.0.0
